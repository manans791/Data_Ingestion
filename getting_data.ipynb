{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Authentication successful!\n",
      "‚úÖ Retrieved data for Kabutops (ID 141)\n",
      "‚úÖ Retrieved data for Aerodactyl (ID 142)\n",
      "‚úÖ Retrieved data for Snorlax (ID 143)\n",
      "‚úÖ Retrieved data for Articuno (ID 144)\n",
      "‚úÖ Retrieved data for Zapdos (ID 145)\n",
      "‚úÖ Retrieved data for Moltres (ID 146)\n",
      "‚úÖ Retrieved data for Dratini (ID 147)\n",
      "‚úÖ Retrieved data for Dragonair (ID 148)\n",
      "‚úÖ Retrieved data for Dragonite (ID 149)\n",
      "‚úÖ Retrieved data for Mewtwo (ID 150)\n",
      "üìÑ Data appended to 'pokemon_data.csv' successfully! Next batch starts from Pok√©mon 151.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python installation\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Data successfully uploaded to BigQuery table pokemons-455012.Pokemon_Master.Master_Data!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set Google Cloud Credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"F:\\project\\pokemons-455012-175f0c65518c.json\"\n",
    "\n",
    "# Google Cloud configurations\n",
    "PROJECT_ID = \"pokemons-455012\"  # Replace with your GCP project ID\n",
    "DATASET_ID = \"Pokemon_Master\"\n",
    "TABLE_ID = \"Master_Data\"\n",
    "\n",
    "CSV_FILENAME = \"pokemon_data.csv\"\n",
    "PROGRESS_FILE = \"progress.txt\"\n",
    "\n",
    "# Initialize BigQuery Client\n",
    "try:\n",
    "    client = bigquery.Client()\n",
    "    print(\"‚úÖ Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Authentication failed: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Get the last fetched Pok√©mon index\n",
    "if os.path.exists(PROGRESS_FILE):\n",
    "    with open(PROGRESS_FILE, \"r\") as f:\n",
    "        start_index = int(f.read().strip())\n",
    "else:\n",
    "    start_index = 1  # Start from the first Pok√©mon\n",
    "\n",
    "# Fetch next 10 Pok√©mon\n",
    "end_index = start_index + 9\n",
    "\n",
    "# Check if CSV file exists\n",
    "file_exists = os.path.exists(CSV_FILENAME)\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(CSV_FILENAME, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers if the file doesn't exist\n",
    "    if not file_exists:\n",
    "        writer.writerow([\"ID\", \"Name\", \"Type(s)\", \"Height\", \"Weight\", \"Base XP\", \"Abilities\"])\n",
    "\n",
    "    # Fetch Pok√©mon data from PokeAPI\n",
    "    for pokemon_id in range(start_index, end_index + 1):\n",
    "        url = f\"https://pokeapi.co/api/v2/pokemon/{pokemon_id}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Extract relevant details\n",
    "            name = data[\"name\"].capitalize()\n",
    "            types = \", \".join([t[\"type\"][\"name\"] for t in data[\"types\"]])\n",
    "            height = data[\"height\"]\n",
    "            weight = data[\"weight\"]\n",
    "            base_xp = data[\"base_experience\"]\n",
    "            abilities = \", \".join([a[\"ability\"][\"name\"] for a in data[\"abilities\"]])\n",
    "\n",
    "            # Append data to CSV\n",
    "            writer.writerow([pokemon_id, name, types, height, weight, base_xp, abilities])\n",
    "            print(f\"‚úÖ Retrieved data for {name} (ID {pokemon_id})\")\n",
    "\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to fetch Pok√©mon ID {pokemon_id} (Error {response.status_code})\")\n",
    "\n",
    "# Update progress file for next batch\n",
    "with open(PROGRESS_FILE, \"w\") as f:\n",
    "    f.write(str(end_index + 1))\n",
    "\n",
    "print(f\"üìÑ Data appended to '{CSV_FILENAME}' successfully! Next batch starts from Pok√©mon {end_index + 1}.\")\n",
    "\n",
    "# Upload CSV to BigQuery\n",
    "def upload_to_bigquery():\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "\n",
    "    try:\n",
    "        # Read CSV into Pandas DataFrame\n",
    "        df = pd.read_csv(CSV_FILENAME)\n",
    "\n",
    "        # Remove duplicates (if any) before uploading\n",
    "        df.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
    "\n",
    "        # Define BigQuery Schema\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            schema=[\n",
    "                bigquery.SchemaField(\"ID\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"Name\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"Type\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"Height\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"Weight\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"Base XP\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"Abilities\", \"STRING\"),\n",
    "            ],\n",
    "            write_disposition=\"WRITE_TRUNCATE\",  # Append new data\n",
    "        )\n",
    "\n",
    "        # Load DataFrame into BigQuery\n",
    "        job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "        job.result()  # Wait for the job to complete\n",
    "\n",
    "        print(f\"üöÄ Data successfully uploaded to BigQuery table {table_id}!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to upload to BigQuery: {e}\")\n",
    "\n",
    "# Run upload function\n",
    "upload_to_bigquery()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
